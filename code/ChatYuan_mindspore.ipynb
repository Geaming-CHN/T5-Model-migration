{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import mindspore\n",
    "\n",
    "os.environ['HTTP_PROXY'] = 'http://172.26.1.159:1090'\n",
    "os.environ['HTTPS_PROXY'] = 'http://172.26.1.159:1090'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  text = text.replace(\"\\n\", \"\\\\n\").replace(\"\\t\", \"\\\\t\")\n",
    "  return text\n",
    "\n",
    "def postprocess(text):\n",
    "  return text.replace(\"\\\\n\", \"\\n\").replace(\"\\\\t\", \"\\t\").replace('%20','  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"美国的首都是哪座城市\"\n",
    "text = f\"用户：{text}\\n小元： \"\n",
    "text = text.strip()\n",
    "text = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/home/geaming/.cache/huggingface/hub/models--ClueAI--ChatYuan-large-v2/snapshots/f566922340539c4c6a8e0dd86c5472155f07d367/spiece.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "\n",
    "class ChatYuanTokenizer():\n",
    "\n",
    "    def __init__(self, path) -> None:\n",
    "        self._tokenizer = spm.SentencePieceProcessor()\n",
    "        self._tokenizer.Load(path)\n",
    "\n",
    "    def _tokenize(self, text_input):\n",
    "        \"\"\"\n",
    "        Returns a tokenized string.\n",
    "        \"\"\"\n",
    "        tokens_ids = self._tokenizer.EncodeAsIds(text_input)\n",
    "        tokens_ids = mindspore.Tensor(tokens_ids, dtype=mindspore.int64)\n",
    "        tokens_ids = tokens_ids.unsqueeze(dim=0)\n",
    "        # return ids\n",
    "        return tokens_ids\n",
    "\n",
    "    def _decode(self, tokens_ids):\n",
    "        return self._tokenizer.DecodeIds(tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ChatYuanTokenizer(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================encoding对齐====================\n",
      "[[   12   623     5 11026  4627    15  1843   939   399     7    51   158\n",
      "      5]]\n"
     ]
    }
   ],
   "source": [
    "# encoding对齐\n",
    "print(\"encoding对齐\".center(50, \"=\"))\n",
    "encoding = tokenizer._tokenize(text_input=text)\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================model对齐======================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0 14958    10  4627    15 11646 14376     6     1]\n"
     ]
    }
   ],
   "source": [
    "# model对齐\n",
    "print(\"model对齐\".center(50, \"=\"))\n",
    "from mindnlp.models import T5Config, T5ForConditionalGeneration\n",
    "\n",
    "config_path = r\"/home/geaming/.cache/huggingface/hub/models--ClueAI--ChatYuan-large-v2/snapshots/f566922340539c4c6a8e0dd86c5472155f07d367/config.json\"\n",
    "\n",
    "\n",
    "with open(config_path, encoding='utf-8') as config:\n",
    "    config = json.load(config)\n",
    "\n",
    "ms_config = T5Config(**config)\n",
    "ms_model = T5ForConditionalGeneration(ms_config)\n",
    "\n",
    "# params\n",
    "ms_dict = mindspore.load_checkpoint('/home/geaming/.cache/huggingface/hub/models--ClueAI--ChatYuan-large-v2/snapshots/f566922340539c4c6a8e0dd86c5472155f07d367/chatyuan_model.ckpt')\n",
    "param_not_load = mindspore.load_param_into_net(ms_model, ms_dict)\n",
    "\n",
    "outputs = ms_model.generate(encoding, output_scores=False, max_new_tokens=1024, num_beams=1, length_penalty=0.6)\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================decoding对齐====================\n",
      "美国的首都是华盛顿特区。\n"
     ]
    }
   ],
   "source": [
    "# decoding对齐\n",
    "print(\"decoding对齐\".center(50, \"=\"))\n",
    "print(tokenizer._decode(outputs[0].asnumpy().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt转换\n",
    "# import logging\n",
    "# def torch_to_mindspore(pth_file, size:str=None):\n",
    "#     try:\n",
    "#         import torch\n",
    "#     except:\n",
    "#         raise ImportError(f\"'import torch' failed, please install torch by \"\n",
    "#                           f\"`pip install torch` or instructions from 'https://pytorch.org'\")\n",
    "\n",
    "#     size = \"mindspore\" if not size else size # rename ckpt\n",
    "\n",
    "#     from mindspore import Tensor\n",
    "#     from mindspore.train.serialization import save_checkpoint\n",
    "\n",
    "#     logging.info('Starting checkpoint conversion.')\n",
    "#     ms_ckpt = []\n",
    "#     state_dict = torch.load(pth_file, map_location=torch.device('cpu'))\n",
    "\n",
    "#     for k, v in state_dict.items():\n",
    "#         if 'shared.weight' in k:\n",
    "#             k = k.replace('shared.weight', 'decoder.embed_tokens.embedding_table')\n",
    "#         if 'relative_attention_bias.weight' in k:\n",
    "#             k = k.replace('relative_attention_bias.weight', 'relative_attention_bias.embedding_table')\n",
    "#         ms_ckpt.append({'name': k, 'data': Tensor(v.numpy())})\n",
    "\n",
    "#     ms_ckpt_path = pth_file.replace('.bin','.ckpt')\n",
    "#     ms_ckpt_path = ms_ckpt_path.replace('pytorch',size)\n",
    "#     try:\n",
    "#         save_checkpoint(ms_ckpt, ms_ckpt_path)\n",
    "#     except:\n",
    "#         raise RuntimeError(f'Save checkpoint to {ms_ckpt_path} failed, please checkout the path.')\n",
    "\n",
    "#     return ms_ckpt_path\n",
    "\n",
    "# torch_to_mindspore(\"/home/geaming/.cache/huggingface/hub/models--ClueAI--ChatYuan-large-v2/snapshots/f566922340539c4c6a8e0dd86c5472155f07d367/pytorch_model.bin\", \"chatyuan\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
