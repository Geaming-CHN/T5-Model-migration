{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore, torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(o1, o2, loss = 1e-3, prefix = '-'):\n",
    "    \"\"\"递归判断输出是否对齐\"\"\"\n",
    "    prefix += '-'\n",
    "    if (isinstance(o1, tuple)):\n",
    "        for i in range(len(o1)):\n",
    "            judge(o1[i], o2[i], loss=loss, prefix=prefix)\n",
    "    elif (isinstance(o1,mindspore.Tensor)):\n",
    "        print(f\"{prefix}{np.allclose(o1.asnumpy(), o2.detach().numpy(), loss, loss)}\")\n",
    "    else:\n",
    "        print(f\"{type(o1)}-{type(o2)}:{o1==o2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_url\n",
    "\n",
    "path = \"/home/data/T5ckpt\"\n",
    "\n",
    "def download_script(size:str):\n",
    "    \"\"\"print wget to download files of a pretrained model\"\"\"\n",
    "    print(f\"wget {hf_hub_url(repo_id=size, filename='config.json')} -P {path}/{size}\")\n",
    "    print(f\"wget {hf_hub_url(repo_id=size, filename='tokenizer.json')} -P {path}/{size}\")\n",
    "    print(f\"wget {hf_hub_url(repo_id=size, filename='pytorch_model.bin')} -P {path}/{size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget https://huggingface.co/t5-small/resolve/main/config.json -P /home/data/T5ckpt/t5-small\n",
      "wget https://huggingface.co/t5-small/resolve/main/tokenizer.json -P /home/data/T5ckpt/t5-small\n",
      "wget https://huggingface.co/t5-small/resolve/main/pytorch_model.bin -P /home/data/T5ckpt/t5-small\n"
     ]
    }
   ],
   "source": [
    "download_script(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "def torch_to_mindspore(pth_file, size:str=None):\n",
    "    try:\n",
    "        import torch\n",
    "    except:\n",
    "        raise ImportError(f\"'import torch' failed, please install torch by \"\n",
    "                          f\"`pip install torch` or instructions from 'https://pytorch.org'\")\n",
    "\n",
    "    size = \"mindspore\" if not size else size # rename ckpt\n",
    "\n",
    "    from mindspore import Tensor\n",
    "    from mindspore.train.serialization import save_checkpoint\n",
    "\n",
    "    logging.info('Starting checkpoint conversion.')\n",
    "    ms_ckpt = []\n",
    "    state_dict = torch.load(pth_file, map_location=torch.device('cpu'))\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        if 'shared.weight' in k:\n",
    "            k = k.replace('shared.weight', 'decoder.embed_tokens.embedding_table')\n",
    "        if 'relative_attention_bias.weight' in k:\n",
    "            k = k.replace('relative_attention_bias.weight', 'relative_attention_bias.embedding_table')\n",
    "        ms_ckpt.append({'name': k, 'data': Tensor(v.numpy())})\n",
    "\n",
    "    ms_ckpt_path = pth_file.replace('.bin','.ckpt')\n",
    "    ms_ckpt_path = ms_ckpt_path.replace('pytorch',size)\n",
    "    try:\n",
    "        save_checkpoint(ms_ckpt, ms_ckpt_path)\n",
    "    except:\n",
    "        raise RuntimeError(f'Save checkpoint to {ms_ckpt_path} failed, please checkout the path.')\n",
    "\n",
    "    return ms_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/daiyuxin/ljm_script/codespace/t5_ckpt/t5-small/t5-small_model.ckpt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_to_mindspore(\"/home/daiyuxin/ljm_script/codespace/t5_ckpt/t5-small/pytorch_model.bin\", \"t5-small\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ljm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
